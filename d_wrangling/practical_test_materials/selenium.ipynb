{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e734a3",
   "metadata": {},
   "source": [
    "```ruby\n",
    "\n",
    "               __                 __               \n",
    "  ______ ____ |  |   ____   ____ |__|__ __  _____  \n",
    " /  ___// __ \\|  | _/ __ \\ /    \\|  |  |  \\/     \\ \n",
    " \\___ \\\\  ___/|  |_\\  ___/|   |  \\  |  |  /  Y Y  \\\n",
    "/____  >\\___  >____/\\___  >___|  /__|____/|__|_|  /\n",
    "     \\/     \\/          \\/     \\/               \\/ \n",
    "```\n",
    "~ a guide to selenium ____-_ðŸ–‹\n",
    "\n",
    "____table of contents\n",
    "* [imports](#imports)\n",
    "* [setup webdriver](#setup-webdriver)\n",
    "* [finding elements](#finding-elements)\n",
    "* [loop & extract data](#loop--extract-data)\n",
    "* [wait for elements (optional)](#wait-for-elements-optional)\n",
    "* [saving stuff](#saving-stuff)\n",
    "* [finish & close browser](#finish--close-browser)\n",
    "* [exercise one](#exercise-one)\n",
    "* [exercise two](#exercise-two)\n",
    "* [exercise two but with pagination](#exercise-two-but-with-pagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium requests webdriver-manager pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725171ca",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "016f435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By # 'By' is used to locate elements\n",
    "from selenium.webdriver.chrome.service import Service # 'Service' is used to manage the ChromeDriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafa67e",
   "metadata": {},
   "source": [
    "## setup webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: for chrome, adjust path if needed\n",
    "service = Service(\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "driver.get(\"https://example.com\")\n",
    "\n",
    "# NOTE: for edge\n",
    "# from selenium.webdriver.edge.service import Service\n",
    "# service = Service(\"msedgedriver.exe\")\n",
    "# driver = webdriver.Edge(service=service)\n",
    "\n",
    "# NOTE: for mac\n",
    "# service = Service()  # Selenium will try to find chromedriver in your PATH\n",
    "# driver = webdriver.Chrome(service=service)\n",
    "# driver.get(\"https://www.example.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507812b",
   "metadata": {},
   "source": [
    "## finding elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec87a79",
   "metadata": {},
   "source": [
    "### by tag, ID, class and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e51b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"928c2ea8efa2e600d7813be1fcf7bedc\", element=\"f.30BA493C03CABC9D03895A97D6D0E550.d.F4A797658EBAD061EB4276A2DBE8115F.e.3\")>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds h1 tags\n",
    "driver.find_element(By.TAG_NAME, \"h1\")\n",
    "\n",
    "# Finds elements by their name attribute\n",
    "# driver.find_element(By.ID, \"exampleId\")\n",
    "\n",
    "# Finds elements by their class name\n",
    "# driver.find_element(By.CLASS_NAME, \"exampleClass\")\n",
    "\n",
    "# Finds elements by link text\n",
    "# driver.find_element(By.LINK_TEXT, \"Example Link\")\n",
    "\n",
    "# Finds elements by partial link text\n",
    "# driver.find_element(By.PARTIAL_LINK_TEXT, \"Example\")\n",
    "\n",
    "# Finds elements by tag name\n",
    "# driver.find_elements(By.TAG_NAME, \"p\")  # Returns a list of all <p> elements\n",
    "\n",
    "# Finds elements by name\n",
    "# driver.find_elements(By.NAME, \"exampleName\")  # Returns a list of all elements with name=\"exampleName\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e925b7",
   "metadata": {},
   "source": [
    "### by css selector or xpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad71e59",
   "metadata": {},
   "source": [
    "Basic Syntax\n",
    "\n",
    "| XPath Syntax | Description                                                                 |\n",
    "|--------------|-----------------------------------------------------------------------------|\n",
    "| `/`          | Selects from the root node.                                                 |\n",
    "| `//`         | Selects nodes in the document from the current node that match the selection no matter where they are. |\n",
    "| `.`          | Selects the current node.                                                   |\n",
    "| `..`         | Selects the parent of the current node.                                     |\n",
    "| `@`          | Used to select attributes.                                                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "672f2d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"928c2ea8efa2e600d7813be1fcf7bedc\", element=\"f.30BA493C03CABC9D03895A97D6D0E550.d.F4A797658EBAD061EB4276A2DBE8115F.e.3\")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element(By.CSS_SELECTOR, \"h1\")\n",
    "driver.find_element(By.XPATH, \"//h1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1bc4a4",
   "metadata": {},
   "source": [
    "### find multiple elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = driver.find_elements(By.CLASS_NAME, \"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c41efc",
   "metadata": {},
   "source": [
    "## loop & extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c718351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "articles = driver.find_elements(By.CLASS_NAME, \"article\")\n",
    "for article in articles:\n",
    "    title = article.find_element(By.TAG_NAME, \"h2\").text\n",
    "    date = article.find_element(By.CLASS_NAME, \"date\").text\n",
    "    data.append([title.strip(), date.strip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c79dc",
   "metadata": {},
   "source": [
    "## wait for elements (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, \"someId\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78efc6f3",
   "metadata": {},
   "source": [
    "## saving stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f27217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Title\", \"Date\"])\n",
    "df.to_csv(\"output.csv\", index=False) # Save as CSV\n",
    "df.to_excel(\"output.xlsx\", index=False) # Save as Excel\n",
    "\n",
    "# df.to_json(\"output.json\", orient=\"records\", lines=True) # Save as JSON\n",
    "# df.to_html(\"output.html\", index=False) # Save as HTML\n",
    "# df.to_sql(\"table_name\", con=connection, if_exists=\"replace\", index=False) # Save to SQL database\n",
    "# product_list_df.to_csv('study_desks.txt', index=False, sep='\\t') # to txt, tab-separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7ef5f",
   "metadata": {},
   "source": [
    "## navigate pages (pagination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b0e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, 4):\n",
    "    url = f\"https://example.com/page/{page}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # allow time to load\n",
    "\n",
    "    articles = driver.find_elements(By.CLASS_NAME, \"article\")\n",
    "    for article in articles:\n",
    "        title = article.find_element(By.TAG_NAME, \"h2\").text\n",
    "        date = article.find_element(By.CLASS_NAME, \"date\").text\n",
    "        data.append([title.strip(), date.strip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8b7aa",
   "metadata": {},
   "source": [
    "## finish & close browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee9860",
   "metadata": {},
   "source": [
    "## exercise one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89ee5a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 books\n",
      "                          title                 author\n",
      "0        A CURSE CARVED IN BONE  by Danielle L. Jensen\n",
      "1                    THE TENANT     by Freida McFadden\n",
      "2       THE EMPEROR OF GLADNESS         by Ocean Vuong\n",
      "3      GREAT BIG BEAUTIFUL LIFE         by Emily Henry\n",
      "4              CAN'T GET ENOUGH        by Kennedy Ryan\n",
      "5             ONE GOLDEN SUMMER      by Carley Fortune\n",
      "6                    THE DEVILS     by Joe Abercrombie\n",
      "7                   FEVER BEACH        by Carl Hiaasen\n",
      "8   REMARKABLY BRIGHT CREATURES     by Shelby Van Pelt\n",
      "9            SHIELD OF SPARROWS        by Devney Perry\n",
      "10                   MY FRIENDS     by Fredrik Backman\n",
      "11                   ONYX STORM      by Rebecca Yarros\n",
      "12          MARBLE HALL MURDERS    by Anthony Horowitz\n",
      "13                  FOURTH WING      by Rebecca Yarros\n",
      "14          I HOPE YOU REMEMBER         by Josie Balka\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "url = \"https://www.nytimes.com/books/best-sellers/combined-print-and-e-book-fiction/\"\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# parse and extract html\n",
    "books = driver.find_elements(By.CSS_SELECTOR, \"li.css-sggj6j\")\n",
    "print(f\"Found {len(books)} books\")\n",
    "\n",
    "book_list = []\n",
    "for book in books:\n",
    "    try:\n",
    "        title = book.find_element(By.CSS_SELECTOR, \"h3.css-2jegzb\").text\n",
    "        author = book.find_element(By.CSS_SELECTOR, \"p.css-1aaqvca\").text\n",
    "\n",
    "        data = {\n",
    "            \"title\": title,\n",
    "            \"author\": author\n",
    "        }\n",
    "        book_list.append(data)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"Element not found in one of the entries:\", e)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "book_list_df = pd.DataFrame(book_list)\n",
    "print(book_list_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "book_list_df.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cd36d",
   "metadata": {},
   "source": [
    "## exercise two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7f32afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 products\n",
      "\n",
      "Extracted Product Information:\n",
      "Name: INDEX AGENT OFFICE CHAIR (HIGH BACK), Price: S$199.00\n",
      "Name: COOLERMASTER CMI-GCR2C-GY CALIBER R2C GAMING CHAIR WITH COOL IN TECH, Price: S$349.00\n",
      "Name: COOLERMASTER CMI-GCX1C-GY CALIBER X1C GAMING CHAIR WITH COOL IN TECH, Price: S$399.00\n",
      "Name: ORTHO BACK BACK SUPPORT - ASSORTED COLOUR, Price: S$77.00\n",
      "Name: JOURNALIST OFFICE CHAIR, Price: S$89.00\n",
      "Name: INDEX TEMPO MESH OFFICE CHAIR, Price: S$129.00\n",
      "Name: MORGEN MESH CHAIR (BLACK), Price: S$139.00\n",
      "Name: MORGEN MESH CHAIR (BLUE), Price: S$139.00\n",
      "Name: HEALING ORTHO BACK FOLDING CHAIR, Price: S$148.00\n",
      "Name: CURVO HOME OFFICE CHAIR BLACK MID BACK CHAIR, Price: S$198.00\n",
      "Name: CURVO HOME OFFICE CHAIR GREY MID BACK CHAIR, Price: S$198.00\n",
      "Name: INDEX EXECUTIVE HIGH BACK OFFICE CHAIR, Price: S$199.00\n",
      "Name: CELLO MID BACK STUDY CHAIR - BLACK, Price: S$228.00\n",
      "Name: MOLLER HI BACK DIRECTOR MESH CHAIR, Price: S$228.00\n",
      "Name: INDEX GRIS OFFICE CHAIR, Price: S$229.00\n",
      "Name: INDEX FORUMER HIGH BACK OFFICE CHAIR, Price: S$229.00\n",
      "\n",
      "Pandas DataFrame:\n",
      "                                                 name     price\n",
      "0                INDEX AGENT OFFICE CHAIR (HIGH BACK)  S$199.00\n",
      "1   COOLERMASTER CMI-GCR2C-GY CALIBER R2C GAMING C...  S$349.00\n",
      "2   COOLERMASTER CMI-GCX1C-GY CALIBER X1C GAMING C...  S$399.00\n",
      "3           ORTHO BACK BACK SUPPORT - ASSORTED COLOUR   S$77.00\n",
      "4                             JOURNALIST OFFICE CHAIR   S$89.00\n",
      "5                       INDEX TEMPO MESH OFFICE CHAIR  S$129.00\n",
      "6                           MORGEN MESH CHAIR (BLACK)  S$139.00\n",
      "7                            MORGEN MESH CHAIR (BLUE)  S$139.00\n",
      "8                    HEALING ORTHO BACK FOLDING CHAIR  S$148.00\n",
      "9        CURVO HOME OFFICE CHAIR BLACK MID BACK CHAIR  S$198.00\n",
      "10        CURVO HOME OFFICE CHAIR GREY MID BACK CHAIR  S$198.00\n",
      "11             INDEX EXECUTIVE HIGH BACK OFFICE CHAIR  S$199.00\n",
      "12                 CELLO MID BACK STUDY CHAIR - BLACK  S$228.00\n",
      "13                 MOLLER HI BACK DIRECTOR MESH CHAIR  S$228.00\n",
      "14                            INDEX GRIS OFFICE CHAIR  S$229.00\n",
      "15               INDEX FORUMER HIGH BACK OFFICE CHAIR  S$229.00\n",
      "\n",
      "Data saved to 'furniture_products.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "url = \"https://www.courts.com.sg/furniture/furniture/study-desks\"\n",
    "\n",
    "# Setup Chrome WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "try:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Allow time for the page to load\n",
    "\n",
    "    # Find all product list items\n",
    "    products = driver.find_elements(By.CSS_SELECTOR, \"li[class = 'item product product-item']\")\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    product_list = []\n",
    "    for product in products:\n",
    "        try:\n",
    "            # Extract product name\n",
    "            product_name_element = product.find_element(By.CSS_SELECTOR, \"h3[class = 'product name product-item-name']\")\n",
    "            product_name = product_name_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            product_name = \"N/A\"\n",
    "\n",
    "        current_price = \"N/A\"\n",
    "        try:\n",
    "            # Check for special price\n",
    "            special_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'special-price']\")\n",
    "            current_price_element = special_price_element.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "            current_price = current_price_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                # If no special price, get the regular price\n",
    "                regular_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "                current_price = regular_price_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                current_price = \"N/A\"\n",
    "\n",
    "        product_info = {\n",
    "            'name': product_name,\n",
    "            'price': current_price\n",
    "        }\n",
    "        product_list.append(product_info)\n",
    "\n",
    "    # Print the extracted data\n",
    "    print(\"\\nExtracted Product Information:\")\n",
    "    for item in product_list:\n",
    "        print(f\"Name: {item['name']}, Price: {item['price']}\")\n",
    "\n",
    "    # Optionally, convert the list of dictionaries to a Pandas DataFrame\n",
    "    df = pd.DataFrame(product_list)\n",
    "    print(\"\\nPandas DataFrame:\")\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"furniture_products.csv\", index=False)\n",
    "    print(\"\\nData saved to 'furniture_products.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f091d2",
   "metadata": {},
   "source": [
    "## exercise two but with pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f342f",
   "metadata": {},
   "source": [
    "### w page button 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b79100a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Page 1 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=1\n",
      "Found 16 products on this page\n",
      "\n",
      "--- Scraping Page 2 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=2\n",
      "Found 16 products on this page\n",
      "\n",
      "--- Scraping Page 3 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=3\n",
      "Found 14 products on this page\n",
      "\n",
      "Scraping completed. Reached the specified limit of 3 pages.\n",
      "\n",
      "Total products extracted: 46\n",
      "\n",
      "Pandas DataFrame:\n",
      "                                                 name       price\n",
      "0                INDEX AGENT OFFICE CHAIR (HIGH BACK)    S$199.00\n",
      "1   COOLERMASTER CMI-GCR2C-GY CALIBER R2C GAMING C...    S$349.00\n",
      "2   COOLERMASTER CMI-GCX1C-GY CALIBER X1C GAMING C...    S$399.00\n",
      "3           ORTHO BACK BACK SUPPORT - ASSORTED COLOUR     S$77.00\n",
      "4                             JOURNALIST OFFICE CHAIR     S$89.00\n",
      "5                       INDEX TEMPO MESH OFFICE CHAIR    S$129.00\n",
      "6                           MORGEN MESH CHAIR (BLACK)    S$139.00\n",
      "7                            MORGEN MESH CHAIR (BLUE)    S$139.00\n",
      "8                    HEALING ORTHO BACK FOLDING CHAIR    S$148.00\n",
      "9        CURVO HOME OFFICE CHAIR BLACK MID BACK CHAIR    S$198.00\n",
      "10        CURVO HOME OFFICE CHAIR GREY MID BACK CHAIR    S$198.00\n",
      "11             INDEX EXECUTIVE HIGH BACK OFFICE CHAIR    S$199.00\n",
      "12                 CELLO MID BACK STUDY CHAIR - BLACK    S$228.00\n",
      "13                 MOLLER HI BACK DIRECTOR MESH CHAIR    S$228.00\n",
      "14                            INDEX GRIS OFFICE CHAIR    S$229.00\n",
      "15               INDEX FORUMER HIGH BACK OFFICE CHAIR    S$229.00\n",
      "16                       MACON ORTHO BACK STUDY CHAIR    S$248.00\n",
      "17                       INDEX APPRECIER OFFICE CHAIR    S$299.00\n",
      "18             SIHOO KLAUS PLUS ALL MESH OFFICE CHAIR    S$398.00\n",
      "19      ASUS SL201 ROG AETHON ROG AETHON GAMING CHAIR    S$399.00\n",
      "20                            INDEX BRUN OFFICE CHAIR    S$399.00\n",
      "21                INDEX OWEN OFFICE CHAIR - HIGH BACK    S$399.00\n",
      "22              READER 2 IN 1 ERGONOMIC STUDY SET-RED    S$419.00\n",
      "23  RAZER RZ38-05310100-R3UA ISKUR V2 X - GAMING C...    S$459.00\n",
      "24  RAZER RZ38-05310200-R3UA ISKUR V2 X - GAMING C...    S$459.00\n",
      "25                          JACK MID BACK STUDY CHAIR    S$488.00\n",
      "26                        KELLY HIGH BACK STUDY CHAIR    S$528.00\n",
      "27            SIHOO CARL ALL MESH OFFICE CHAIR (GREY)    S$528.00\n",
      "28  CARL HOME OFFICE CHAIR BLACK HIGH BACK ERGONOM...    S$528.00\n",
      "29             ACTON HIGH BACK ERGONOMIC OFFICE CHAIR    S$549.00\n",
      "30                        MEDWIN PREMIUM OFFICE CHAIR    S$678.00\n",
      "31                        BOGART HI BACK OFFICE CHAIR    S$688.00\n",
      "32  RAZER RZ38-02770200-R3U1 (BLACK) ISKUR GAMING ...    S$749.90\n",
      "33  ASUS SL301 ROG CHARIOT X BLACK ROG CHARIOT X R...    S$789.00\n",
      "34  ASUS SL301 ROG CHARIOT X GREY ROG CHARIOT X RG...    S$789.00\n",
      "35  ASUS SL400C ROG DESTRIER CORE/BK/WW ROG DESTRI...    S$799.00\n",
      "36  RAZER RZ38-04950100-R3U1 FUJIN â€“ MESH GAMING C...    S$939.00\n",
      "37  RAZER RZ38-04900300-R3U1 RAZER ISKUR V2 - DARK...    S$949.00\n",
      "38  RAZER RZ38-04900200-R3U1 RAZER ISKUR V2 - BLAC...    S$949.00\n",
      "39  RAZER RZ38-04900100-R3U1 RAZER ISKUR V2 GAMING...    S$949.00\n",
      "40  ASUS SL400 ROG DESTRIER ROG DESTRIER ERGO GAMI...    S$999.00\n",
      "41  OSIM OS-8213M (BLACK) UTHRONE S GAMING CHAIR B...    S$999.00\n",
      "42  RAZER RZ38-04940100-R3U1 FUJIN PRO-FULLY ADJUS...  S$1,499.00\n",
      "43  OSIM OS8215 (BLACK) UTHRONE V GAMING MASSAGE C...  S$1,599.00\n",
      "44                           APPRENTICE OFFICE CHAIRS    S$399.00\n",
      "45                 INDEX BARON HIGH BACK OFFICE CHAIR    S$499.00\n",
      "\n",
      "All data saved to 'all_furniture_products_pp.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "url = \"https://www.courts.com.sg/furniture/furniture/study-desks\"\n",
    "\n",
    "# --- USER CONFIGURATION ---\n",
    "# Set the maximum number of pages you want to scrape.\n",
    "# For example, set to 1 to scrape only the first page.\n",
    "# Set to 5 to scrape pages 1 through 5.\n",
    "PAGES_TO_SCRAPE = 3 # <--- CHANGE THIS VALUE TO YOUR DESIRED NUMBER OF PAGES\n",
    "# --------------------------\n",
    "\n",
    "# Setup Chrome WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "all_product_data = []  # Initialize an empty list to store data from all pages\n",
    "page_number = 1  # Start with the first page\n",
    "\n",
    "try:\n",
    "    # Loop through pages until the specified limit is reached OR no more products are found\n",
    "    while page_number <= PAGES_TO_SCRAPE:\n",
    "        print(f\"\\n--- Scraping Page {page_number} ---\")\n",
    "        # Construct the URL for the current page using the page number parameter 'p'\n",
    "        current_url = f\"{url}?p={page_number}\"\n",
    "        print(f\"Navigating to: {current_url}\")\n",
    "        driver.get(current_url)\n",
    "        time.sleep(5)  # Allow sufficient time for the page to load completely\n",
    "\n",
    "        # Find all product list items on the current page\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"li[class = 'item product product-item']\")\n",
    "        print(f\"Found {len(products)} products on this page\")\n",
    "\n",
    "        # If no products are found on the current page, it means we have reached the end\n",
    "        # of available products, even if PAGES_TO_SCRAPE hasn't been met.\n",
    "        if not products:\n",
    "            print(\"No more products found on this page. Stopping scraping.\")\n",
    "            break # Exit the loop if no products are found\n",
    "\n",
    "        product_list = []  # Initialize a list to store products from the current page\n",
    "        for product in products:\n",
    "            try:\n",
    "                # Extract product name\n",
    "                product_name_element = product.find_element(By.CSS_SELECTOR, \"h3[class = 'product name product-item-name']\")\n",
    "                product_name = product_name_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                product_name = \"N/A\"\n",
    "\n",
    "            current_price = \"N/A\"\n",
    "            try:\n",
    "                # Check for special price\n",
    "                special_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'special-price']\")\n",
    "                current_price_element = special_price_element.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "                current_price = current_price_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                try:\n",
    "                    # If no special price, get the regular price\n",
    "                    regular_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "                    current_price = regular_price_element.text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    current_price = \"N/A\"\n",
    "\n",
    "            product_info = {\n",
    "                'name': product_name,\n",
    "                'price': current_price\n",
    "            }\n",
    "            product_list.append(product_info)\n",
    "\n",
    "        all_product_data.extend(product_list)  # Add the extracted data from the current page to the main list\n",
    "\n",
    "        # Increment page number for the next iteration\n",
    "        page_number += 1\n",
    "\n",
    "    # Print a message if the loop finished because the page limit was reached\n",
    "    if page_number > PAGES_TO_SCRAPE:\n",
    "        print(f\"\\nScraping completed. Reached the specified limit of {PAGES_TO_SCRAPE} pages.\")\n",
    "\n",
    "\n",
    "    # Print the total number of products extracted across all pages\n",
    "    print(f\"\\nTotal products extracted: {len(all_product_data)}\")\n",
    "\n",
    "    # Convert the list of dictionaries containing all product data into a Pandas DataFrame\n",
    "    df = pd.DataFrame(all_product_data)\n",
    "    print(\"\\nPandas DataFrame:\")\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file named 'all_furniture_products.csv' without the index\n",
    "    df.to_csv(\"all_furniture_products_pp.csv\", index=False)\n",
    "    print(\"\\nAll data saved to 'all_furniture_products_pp.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions that might occur during the scraping process\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Ensure the browser is closed even if an error occurs\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773e4c3",
   "metadata": {},
   "source": [
    "### manipulating url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f635fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Page 1 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=1\n",
      "Found 16 products on this page\n",
      "\n",
      "--- Scraping Page 2 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=2\n",
      "Found 16 products on this page\n",
      "\n",
      "--- Scraping Page 3 ---\n",
      "Navigating to: https://www.courts.com.sg/furniture/furniture/study-desks?p=3\n",
      "Found 14 products on this page\n",
      "\n",
      "Total products extracted: 46\n",
      "\n",
      "Pandas DataFrame:\n",
      "                                                 name       price\n",
      "0                INDEX AGENT OFFICE CHAIR (HIGH BACK)    S$199.00\n",
      "1   COOLERMASTER CMI-GCR2C-GY CALIBER R2C GAMING C...    S$349.00\n",
      "2   COOLERMASTER CMI-GCX1C-GY CALIBER X1C GAMING C...    S$399.00\n",
      "3           ORTHO BACK BACK SUPPORT - ASSORTED COLOUR     S$77.00\n",
      "4                             JOURNALIST OFFICE CHAIR     S$89.00\n",
      "5                       INDEX TEMPO MESH OFFICE CHAIR    S$129.00\n",
      "6                           MORGEN MESH CHAIR (BLACK)    S$139.00\n",
      "7                            MORGEN MESH CHAIR (BLUE)    S$139.00\n",
      "8                    HEALING ORTHO BACK FOLDING CHAIR    S$148.00\n",
      "9        CURVO HOME OFFICE CHAIR BLACK MID BACK CHAIR    S$198.00\n",
      "10        CURVO HOME OFFICE CHAIR GREY MID BACK CHAIR    S$198.00\n",
      "11             INDEX EXECUTIVE HIGH BACK OFFICE CHAIR    S$199.00\n",
      "12                 CELLO MID BACK STUDY CHAIR - BLACK    S$228.00\n",
      "13                 MOLLER HI BACK DIRECTOR MESH CHAIR    S$228.00\n",
      "14                            INDEX GRIS OFFICE CHAIR    S$229.00\n",
      "15               INDEX FORUMER HIGH BACK OFFICE CHAIR    S$229.00\n",
      "16                       MACON ORTHO BACK STUDY CHAIR    S$248.00\n",
      "17                       INDEX APPRECIER OFFICE CHAIR    S$299.00\n",
      "18             SIHOO KLAUS PLUS ALL MESH OFFICE CHAIR    S$398.00\n",
      "19      ASUS SL201 ROG AETHON ROG AETHON GAMING CHAIR    S$399.00\n",
      "20                            INDEX BRUN OFFICE CHAIR    S$399.00\n",
      "21                INDEX OWEN OFFICE CHAIR - HIGH BACK    S$399.00\n",
      "22              READER 2 IN 1 ERGONOMIC STUDY SET-RED    S$419.00\n",
      "23  RAZER RZ38-05310100-R3UA ISKUR V2 X - GAMING C...    S$459.00\n",
      "24  RAZER RZ38-05310200-R3UA ISKUR V2 X - GAMING C...    S$459.00\n",
      "25                          JACK MID BACK STUDY CHAIR    S$488.00\n",
      "26                        KELLY HIGH BACK STUDY CHAIR    S$528.00\n",
      "27            SIHOO CARL ALL MESH OFFICE CHAIR (GREY)    S$528.00\n",
      "28  CARL HOME OFFICE CHAIR BLACK HIGH BACK ERGONOM...    S$528.00\n",
      "29             ACTON HIGH BACK ERGONOMIC OFFICE CHAIR    S$549.00\n",
      "30                        MEDWIN PREMIUM OFFICE CHAIR    S$678.00\n",
      "31                        BOGART HI BACK OFFICE CHAIR    S$688.00\n",
      "32  RAZER RZ38-02770200-R3U1 (BLACK) ISKUR GAMING ...    S$749.90\n",
      "33  ASUS SL301 ROG CHARIOT X BLACK ROG CHARIOT X R...    S$789.00\n",
      "34  ASUS SL301 ROG CHARIOT X GREY ROG CHARIOT X RG...    S$789.00\n",
      "35  ASUS SL400C ROG DESTRIER CORE/BK/WW ROG DESTRI...    S$799.00\n",
      "36  RAZER RZ38-04950100-R3U1 FUJIN â€“ MESH GAMING C...    S$939.00\n",
      "37  RAZER RZ38-04900300-R3U1 RAZER ISKUR V2 - DARK...    S$949.00\n",
      "38  RAZER RZ38-04900200-R3U1 RAZER ISKUR V2 - BLAC...    S$949.00\n",
      "39  RAZER RZ38-04900100-R3U1 RAZER ISKUR V2 GAMING...    S$949.00\n",
      "40  ASUS SL400 ROG DESTRIER ROG DESTRIER ERGO GAMI...    S$999.00\n",
      "41  OSIM OS-8213M (BLACK) UTHRONE S GAMING CHAIR B...    S$999.00\n",
      "42  RAZER RZ38-04940100-R3U1 FUJIN PRO-FULLY ADJUS...  S$1,499.00\n",
      "43  OSIM OS8215 (BLACK) UTHRONE V GAMING MASSAGE C...  S$1,599.00\n",
      "44                           APPRENTICE OFFICE CHAIRS    S$399.00\n",
      "45                 INDEX BARON HIGH BACK OFFICE CHAIR    S$499.00\n",
      "\n",
      "Data from pages 1 to {num_pages_to_scrape} saved to 'furniture_products_page1_to_3.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "url = \"https://www.courts.com.sg/furniture/furniture/study-desks\"\n",
    "num_pages_to_scrape = 3\n",
    "\n",
    "# Setup Chrome WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "all_product_data = []\n",
    "\n",
    "try:\n",
    "    for page_number in range(1, num_pages_to_scrape + 1):\n",
    "        print(f\"\\n--- Scraping Page {page_number} ---\")\n",
    "        current_url = f\"{url}?p={page_number}\"\n",
    "        print(f\"Navigating to: {current_url}\")\n",
    "        driver.get(current_url)\n",
    "        time.sleep(5)  # Allow time for the page to load\n",
    "\n",
    "        # Find all product list items on the current page\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"li[class = 'item product product-item']\")\n",
    "        print(f\"Found {len(products)} products on this page\")\n",
    "\n",
    "        product_list = []\n",
    "        for product in products:\n",
    "            try:\n",
    "                # Extract product name\n",
    "                product_name_element = product.find_element(By.CSS_SELECTOR, \"h3[class = 'product name product-item-name']\")\n",
    "                product_name = product_name_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                product_name = \"N/A\"\n",
    "\n",
    "            current_price = \"N/A\"\n",
    "            try:\n",
    "                # Check for special price\n",
    "                special_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'special-price']\")\n",
    "                current_price_element = special_price_element.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "                current_price = current_price_element.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                try:\n",
    "                    # If no special price, get the regular price\n",
    "                    regular_price_element = product.find_element(By.CSS_SELECTOR, \"span[class = 'price']\")\n",
    "                    current_price = regular_price_element.text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    current_price = \"N/A\"\n",
    "\n",
    "            product_info = {\n",
    "                'name': product_name,\n",
    "                'price': current_price\n",
    "            }\n",
    "            product_list.append(product_info)\n",
    "\n",
    "        all_product_data.extend(product_list)\n",
    "\n",
    "    # Print the total extracted data\n",
    "    print(f\"\\nTotal products extracted: {len(all_product_data)}\")\n",
    "\n",
    "    # Convert the list of dictionaries to a Pandas DataFrame\n",
    "    df = pd.DataFrame(all_product_data)\n",
    "    print(\"\\nPandas DataFrame:\")\n",
    "    print(df)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"furniture_products_page1_to_3.csv\", index=False)\n",
    "    print(\"\\nData from pages 1 to {num_pages_to_scrape} saved to 'furniture_products_page1_to_3.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
