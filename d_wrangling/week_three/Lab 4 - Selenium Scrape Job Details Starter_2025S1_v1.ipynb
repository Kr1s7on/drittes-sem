{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d69432",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This practice covers the steps on how to scrape jobs from Foundit. Using python, selenium, and pandas, we'll be able to extract information from foundit.sg and construct a pandas data frame. Before we begin, let's understand web scraping simply. \n",
    "\n",
    "Imagine if you are trying to get much information about something from various web pages and articles that need to be stored in a suitable format, for instance, an excel file. One way is to go through all those websites and write the useful information to the excel sheets manually. But programmers tend to do it in an easy way which is web scraping. Web scraping is the technique of extracting a large amount of data from different web pages that can be stored in a suitable format.\n",
    "\n",
    "## Scraping job details from Foundit\n",
    "The foundit (formerly Monster) Job Search App is a platform for freshers & experienced job seekers to find their perfect career opportunities. \n",
    "\n",
    "Here are the steps involved:\n",
    "\n",
    "1. Install and import necessary modules\n",
    "2. Send some basic queries like like job title or company name and location to the Foundit website using selenium\n",
    "3. Fetch the current URL after sending the queries to the website using selenium\n",
    "4. Fetch the information about job title, company name, rating, location, simple description, date of posting, etc\n",
    "5. Store this information into a CSV file using pandas\n",
    "\n",
    "\n",
    "## Load Libraries\n",
    "First of all, we need to install some specific modules including a chrome driver for selenium. After installing the chrome driver move it to the working directory.\n",
    "\n",
    "We need to import the libraries that will be used for this practical. Here requests help to send an HTTP request using python, Selenium is an automation tool that helps here to send queries to the website, lxml can convert the page into XML or HTML format. Pandas is to convert the data into a CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9992083d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (4.32.0)\n",
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from selenium) (4.13.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from webdriver_manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver_manager)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: packaging in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from webdriver_manager) (24.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from requests->webdriver_manager) (3.4.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/puolsky/Library/Python/3.9/lib/python/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, webdriver_manager\n",
      "Successfully installed python-dotenv-1.1.0 webdriver_manager-4.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7b75fee",
   "metadata": {},
   "source": [
    "## Sending job title and location using selenium\n",
    "Now let's create a function that sends queries to the web page and returns the current URL. This function opens Foundit using the specified URL as one of its parameters. Then it sends the job title and location to the site using selenium. After that, we'll get a new page and its URL which consists of all the job details related to the job title and location you have specified as its parameters. Lastly, it returns the current URL which consists of jobs and their details so that we can simply scrape it using Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0922d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "813607e2",
   "metadata": {},
   "source": [
    "## Scraping jobs using Beautiful Soup\n",
    "\n",
    "Not all the websites can use BeatuifulSoup to scrape. check https://www.foundit.sg/robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e9445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cf50418",
   "metadata": {},
   "source": [
    "## Scraping jobs using Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff0e7b",
   "metadata": {},
   "source": [
    "The next step is to find the CSS selectors and retrieve the raw text inside the tags that contain these CSS selectors. The CSS selectors given in the code are probably the same on the web page but sometimes it may change.\n",
    "\n",
    "By looping through all the job posts we'll get much information about it. Lastly, we converted the data into a pandas data frame and simply returned it. You'll get the details about the job title, company name, salary, post date and experience. You can save it as a CSV file using df.to_csv(\"jobs.csv\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346983e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be267bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Sending command: employees\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 54] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m         read_response(sock)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 68\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Sending command: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommand\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m send_command(sock, command)\n\u001b[0;32m---> 68\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mread_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Initial server line: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m read_response(sock)\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mread_line\u001b[0;34m(sock)\u001b[0m\n\u001b[1;32m     11\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import struct\n",
    "\n",
    "def send_command(sock, command: str):\n",
    "    # Message format: [type: 1 byte] [length: 4 bytes, little endian] [command as bytes]\n",
    "    cmd_bytes = command.encode()\n",
    "    packet = struct.pack('<BI', 1, len(cmd_bytes)) + cmd_bytes\n",
    "    sock.sendall(packet)\n",
    "\n",
    "def read_line(sock):\n",
    "    line = b''\n",
    "    while not line.endswith(b'\\n'):\n",
    "        chunk = sock.recv(1)\n",
    "        if not chunk:\n",
    "            break\n",
    "        line += chunk\n",
    "    return line.decode()\n",
    "\n",
    "def read_response(sock):\n",
    "    print(\"[+] Server response:\")\n",
    "    while True:\n",
    "        # Peek at next byte\n",
    "        head = sock.recv(1, socket.MSG_PEEK)\n",
    "        if not head:\n",
    "            break\n",
    "        if head == b'\\x05':  # End byte\n",
    "            sock.recv(1)\n",
    "            break\n",
    "        if head == b'\\x03':  # Control/Separator\n",
    "            sock.recv(1)\n",
    "            continue\n",
    "\n",
    "        # Read message\n",
    "        type_byte = sock.recv(1)\n",
    "        if type_byte != b'\\x02':\n",
    "            print(\"[!] Unexpected type:\", type_byte)\n",
    "            break\n",
    "\n",
    "        length_bytes = sock.recv(4)\n",
    "        if len(length_bytes) < 4:\n",
    "            print(\"[!] Incomplete length\")\n",
    "            break\n",
    "        length = struct.unpack('<I', length_bytes)[0]\n",
    "\n",
    "        data = sock.recv(length)\n",
    "        if len(data) < length:\n",
    "            print(\"[!] Incomplete data\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            print(data.decode())\n",
    "        except:\n",
    "            print(data)\n",
    "\n",
    "def main():\n",
    "    host = 'ctf1.sentinel-cyber.sg'\n",
    "    port = 65432\n",
    "\n",
    "    with socket.create_connection((host, port)) as sock:\n",
    "        # Try likely commands — \"flag\" is a good guess\n",
    "        command = \"flag\"\n",
    "        print(f\"[+] Sending command: {command}\")\n",
    "        send_command(sock, command)\n",
    "\n",
    "        response = read_line(sock)\n",
    "        print(f\"[+] Initial server line: {response.strip()}\")\n",
    "\n",
    "        read_response(sock)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
